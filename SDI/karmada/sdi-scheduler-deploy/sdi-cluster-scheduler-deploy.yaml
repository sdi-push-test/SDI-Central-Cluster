---
apiVersion: v1
kind: Namespace
metadata:
  name: sdi-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sdi-scheduler
  namespace: sdi-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: sdi-scheduler
rules:
- apiGroups: [""]              # core
  resources: ["nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["cluster.karmada.io"]
  resources: ["clusters"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["work.karmada.io"]
  resources: ["resourcebindings", "clusterresourcebindings"]
  verbs: ["get", "list", "watch", "update", "patch"]
- apiGroups: ["coordination.k8s.io"]
  resources: ["leases"]
  verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create", "patch", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: sdi-scheduler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: sdi-scheduler
subjects:
- kind: ServiceAccount
  name: sdi-scheduler
  namespace: sdi-system
---
# Note: You need to copy the kubeconfig secret from karmada-system namespace
# kubectl get secret karmada-kubeconfig -n karmada-system -o yaml | \
#   sed 's/namespace: karmada-system/namespace: sdi-system/' | \
#   sed 's/name: karmada-kubeconfig/name: sdi-karmada-kubeconfig/' | \
#   kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: sdi-karmada-kubeconfig
  namespace: sdi-system
type: Opaque
data:
  # This will be populated by copying from karmada-system/karmada-kubeconfig secret
  kubeconfig: ""
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sdi-cluster-scheduler
  namespace: sdi-system
  labels:
    app: sdi-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sdi-scheduler
  template:
    metadata:
      labels:
        app: sdi-scheduler
    spec:
      serviceAccountName: sdi-scheduler
      containers:
        - name: sdi-scheduler
          image: ketidevit2/sdi-cluster-scheduler:1.1.3
          imagePullPolicy: IfNotPresent
          env:
            - name: ANALYSIS_ENGINE_ADDR
              value: "http://sdi-analysis-engine-service.default.svc.cluster.local:5000"
          args:
            - --kubeconfig=/etc/karmada/kubeconfig
            - --scheduler-name=sdi-cluster-scheduler
            - --leader-elect=true
            - --leader-elect-resource-name=sdi-cluster-scheduler
            - --v=3
          resources:
            requests: { cpu: 100m, memory: 128Mi }
            limits:   { cpu: 500m, memory: 512Mi }
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 65532
            runAsGroup: 65532
          volumeMounts:
            - name: karmada-kubeconfig
              mountPath: /etc/karmada
              readOnly: true
      volumes:
        - name: karmada-kubeconfig
          secret:
            secretName: sdi-karmada-kubeconfig
            items:
              - key: kubeconfig
                path: kubeconfig
